import torch
from torch.autograd import Variable
from PIL import Image
import matplotlib.pyplot as plt

from image_utils import preprocess
class SaliencyMap:
    def compute_saliency_maps(self, X, y, model):
        """

        Input:
        - X: Input images; Tensor of shape (N, 3, H, W)
        - y: Labels for X; LongTensor of shape (N,)
        - model: A pretrained CNN that will be used to compute the saliency map.

        Returns:
        - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input
        images.
        """
        model.eval()

        # Wrap the input tensors in Variables
        X_var = Variable(X, requires_grad=True)
        y_var = Variable(y, requires_grad=False)
        #saliency = None
        
        forward = model(X_var)
        score = forward.gather(1, y.view(-1, 1)).squeeze()
        score.backward(torch.ones_like(score))
        saliency = X_var.grad.abs()
        saliency, _ = torch.max(saliency, dim=1)

        return saliency

    def show_saliency_maps(self, X, y, class_names, model):
        # Convert X and y from numpy arrays to Torch Tensors
        X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)
        y_tensor = torch.LongTensor(y)

        # Compute saliency maps for images in X
        saliency = self.compute_saliency_maps(X_tensor, y_tensor, model)
        # Convert the saliency map from Torch Tensor to numpy array and show images
        # and saliency maps together.
        saliency = saliency.numpy()

        N = X.shape[0]
        for i in range(N):
            plt.subplot(2, N, i + 1)
            plt.imshow(X[i])
            plt.axis('off')
            plt.title(class_names[y[i]])
            plt.subplot(2, N, N + i + 1)
            plt.imshow(saliency[i], cmap=plt.cm.gray)
            plt.axis('off')
            plt.gcf().set_size_inches(12, 5)
        plt.savefig('visualization/saliency_map.png', bbox_inches = 'tight')
        #plt.show()
